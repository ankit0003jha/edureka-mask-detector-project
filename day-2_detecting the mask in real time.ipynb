{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the model \n",
    "\n",
    "Before we begin with the detection, we must load the model that we had saved in the previous process using the load_model() by including the path of the .model file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "detector = load_model(r'C:/Users/d/Desktop/ML/dummy.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting the stream for Mask Detection in Real Time \n",
    "\n",
    "To detect the mask in a live stream we will follow the following steps:\n",
    "1. start the video stream \n",
    "2. Capture the frame from the stream\n",
    "3. Resize the frame\n",
    "4. Detect faces in the frame using haarcascade classifier\n",
    "5. Get the predictions using the saved model\n",
    "6. Depending on the results draw rectangle and put text on the faces accordingly\n",
    "\n",
    "The following are some of the important functions that we will use for our process.<br>\n",
    "img_to_array() - Converts the image to a numpy array<br>\n",
    "detectmultiscale() - Detects objects in the image<br>\n",
    "tf.expand_dims() - Inserts a dimension of length 1 and returns a tensor<br>\n",
    "tf.nn.softmax() - used for computing softmax activations<br>\n",
    "numpy.argmax() - returns the indices of the values that are maximum along the x-axis<br>\n",
    "    \n",
    "<strong>Alternatively, you can choose other face detection technique instead of haarcascade, since it is the most basic technique to detect faces. And sometimes the results are not very efficient. \n",
    "You can use the opencv caffe model for face detection for variation in your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy\n",
    "\n",
    "#starting the video stream\n",
    "cap = cv2.VideoCapture(0) \n",
    "\n",
    "#using the XML file for haarcascade classifier\n",
    "classifier = cv2.CascadeClassifier(r\"C:/Users/d/Desktop/ML/haarcascade_frontalface_default.xml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad frame\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-0b82b0d5e026>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bad frame'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_image\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mputText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_image\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"mask\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFONT_HERSHEY_SIMPLEX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "faceCascade = cv2.CascadeClassifier(\"C:/Users/d/Desktop/ML/haarcascade_frontalface_default.xml\")\n",
    "\n",
    "img = cv2.imread(\"C:/Users/d/Pictures/2020-09/ankitjha.JPG\") #Reading an Image\n",
    "\n",
    "img = cv2.resize(img, (1240,640))\n",
    "imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = faceCascade.detectMultiScale(imgGray, 1.1, 4)\n",
    "\n",
    "for x,y,w,h in faces:\n",
    "        try:\n",
    "            face_img = new_image[y:x+h, x:x+w] #getting the coordinates for the face detected\n",
    "            resized= cv2.resize(face_img,(224,224)) #resizing the  face detected to fit into the model in the shape(224,224)\n",
    "            image_array = tf.keras.preprocessing.image.img_to_array(resized) #converting the detected image into an array \n",
    "            image_array = tf.expand_dims(image_array,0) #expanding the dimensions to fit in the model\n",
    "            predictions = detector.predict(image_array) #making predictions on the ROI\n",
    "            score = tf.nn.softmax(predictions[0]) #getting the results \n",
    "            labels = numpy.argmax(score)\n",
    "        except Exception as e:\n",
    "            print('bad frame')\n",
    "            \n",
    "        if labels == 0:\n",
    "            cv2.rectangle(new_image,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            cv2.putText(new_image,\"mask\",(x,y),cv2.FONT_HERSHEY_SIMPLEX,0.8,(0,255,0), 2)\n",
    "        elif labels == 1:\n",
    "            cv2.rectangle(new_image,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "            cv2.putText(new_image,'no_mask',(x,y),cv2.FONT_HERSHEY_SIMPLEX,0.8,(0,0,255), 2)\n",
    "        else:\n",
    "            None\n",
    "#displaying the window after predicting the outcome\n",
    "cv2.imshow('output', img)\n",
    "print(numpy.argmax(score), 100*numpy.max(score))\n",
    "#waitkey to terminate the loop\n",
    "key = cv2.waitKey(10) \n",
    "   \n",
    "#release the stream \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "904 0.18831599736586213\n",
      "904 0.21068069618195295\n",
      "904 0.2403900260105729\n",
      "904 0.2407114952802658\n",
      "904 0.2232866594567895\n",
      "904 0.22811489179730415\n",
      "904 0.1966996118426323\n",
      "904 0.18377542728558183\n",
      "904 0.2206963486969471\n",
      "904 0.17881763633340597\n",
      "904 0.17881763633340597\n",
      "904 0.17881763633340597\n",
      "904 0.17881763633340597\n",
      "904 0.17881763633340597\n",
      "904 0.17881763633340597\n",
      "904 0.2124045044183731\n",
      "904 0.2124045044183731\n",
      "904 0.2124045044183731\n",
      "904 0.2124045044183731\n",
      "904 0.2124045044183731\n",
      "904 0.2124045044183731\n",
      "794 0.2264252630993724\n",
      "794 0.22968081757426262\n",
      "794 0.22232006303966045\n",
      "794 0.23702362086623907\n",
      "794 0.1795584335923195\n",
      "794 0.15480610309168696\n",
      "794 0.14993218937888741\n",
      "794 0.17296250443905592\n",
      "794 0.11933562345802784\n",
      "904 0.13083071680739522\n",
      "904 0.17494969069957733\n",
      "904 0.13999787624925375\n",
      "904 0.13369269436225295\n",
      "904 0.14839483192190528\n",
      "794 0.16970494762063026\n",
      "904 0.13299891725182533\n",
      "904 0.15309159643948078\n",
      "904 0.17253694823011756\n",
      "904 0.1633562962524593\n",
      "904 0.14764659572392702\n",
      "904 0.1600123243406415\n",
      "904 0.14304632786661386\n",
      "904 0.1415127655491233\n",
      "904 0.13887553941458464\n",
      "904 0.13887553941458464\n",
      "904 0.1630786689929664\n",
      "904 0.1528464606963098\n",
      "904 0.12200550409033895\n",
      "904 0.15916565898805857\n",
      "904 0.15916565898805857\n",
      "904 0.19207921577617526\n",
      "904 0.18990628886967897\n",
      "904 0.15941767487674952\n",
      "904 0.2039488172158599\n",
      "904 0.16921937931329012\n",
      "904 0.15913668321445584\n",
      "904 0.18782035913318396\n",
      "904 0.18782035913318396\n",
      "904 0.18782035913318396\n",
      "904 0.18782035913318396\n",
      "904 0.18782035913318396\n",
      "904 0.18782035913318396\n",
      "904 0.21613819990307093\n",
      "904 0.16369118820875883\n",
      "904 0.13823952758684754\n",
      "904 0.14622884336858988\n",
      "904 0.16742735169827938\n",
      "904 0.15644502127543092\n",
      "904 0.17321872292086482\n",
      "904 0.19270379561930895\n",
      "904 0.20596235990524292\n",
      "904 0.17651984235271811\n",
      "904 0.1435628393664956\n",
      "556 0.14153076335787773\n",
      "794 0.13509156415238976\n"
     ]
    }
   ],
   "source": [
    "#using the loop to watch the stream in real time.\n",
    "while True:\n",
    "    (success, frame) = cap.read()  #reading the frame from the stream \n",
    "    new_image = cv2.resize(frame, (frame.shape[1] // 1, frame.shape[0] // 1)) #resizing the frame to speed up the process of detection\n",
    "    face = classifier.detectMultiScale(new_image) #detecting faces from the frame(ROI)\n",
    "    for x,y,w,h in face:\n",
    "        try:\n",
    "            face_img = new_image[y:x+h, x:x+w] #getting the coordinates for the face detected\n",
    "            resized= cv2.resize(face_img,(224,224)) #resizing the  face detected to fit into the model in the shape(224,224)\n",
    "            image_array = tf.keras.preprocessing.image.img_to_array(resized) #converting the detected image into an array \n",
    "            image_array = tf.expand_dims(image_array,0) #expanding the dimensions to fit in the model\n",
    "            predictions = detector.predict(image_array) #making predictions on the ROI\n",
    "            score = tf.nn.softmax(predictions[0]) #getting the results \n",
    "            label = numpy.argmax(score)\n",
    "        except Exception as e:\n",
    "            print('bad frame')\n",
    "            \n",
    "        if label == 0:\n",
    "            cv2.rectangle(new_image,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            cv2.putText(new_image,\"mask\",(x,y),cv2.FONT_HERSHEY_SIMPLEX,0.8,(0,255,0), 2)\n",
    "        elif label == 1:\n",
    "            cv2.rectangle(new_image,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "            cv2.putText(new_image,'no_mask',(x,y),cv2.FONT_HERSHEY_SIMPLEX,0.8,(0,0,255), 2)\n",
    "        else:\n",
    "            None\n",
    "    #displaying the window after predicting the outcome\n",
    "    cv2.imshow('face_window', new_image)\n",
    "    print(numpy.argmax(score), 100*numpy.max(score))\n",
    "    #waitkey to terminate the loop\n",
    "    key = cv2.waitKey(10) \n",
    "    if key == ord('q'):\n",
    "        break\n",
    "#release the stream \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
